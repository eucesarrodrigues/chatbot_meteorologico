import streamlit as st
import google.generativeai as genai
import requests
from google.generativeai.types import FunctionDeclaration, Tool
from dotenv import load_dotenv
import os

load_dotenv()

# --- CONFIGURAÃ‡ÃƒO DA PÃGINA ---
st.set_page_config(
    page_title="Chatbot Clima AI",
    page_icon="ğŸŒ¦ï¸",
    layout="centered"
)

st.title("ğŸŒ¦ï¸ Assistente MeteorolÃ³gico Inteligente")
st.caption("Powered by Google Gemini & Open-Meteo API")

# --- FUNÃ‡Ã•ES DE FERRAMENTA (BACKEND) ---
# (Mesmas funÃ§Ãµes do cÃ³digo anterior, otimizadas para cache se necessÃ¡rio)

WEATHER_MAP = {
    0: "CÃ©u limpo â˜€ï¸", 1: "Predominantemente claro ğŸŒ¤ï¸", 2: "Parcialmente nublado â›…", 3: "Nublado â˜ï¸",
    45: "Nevoeiro ğŸŒ«ï¸", 48: "Nevoeiro com geada â„ï¸", 51: "Garoa leve ğŸŒ§ï¸", 53: "Garoa moderada ğŸŒ§ï¸",
    61: "Chuva fraca â˜”", 63: "Chuva moderada â˜”", 65: "Chuva forte â›ˆï¸",
    80: "Pancadas de chuva ğŸŒ¦ï¸", 95: "Tempestade âš¡", 99: "Tempestade com granizo ğŸŒ¨ï¸"
}

def get_coordinates(city_name):
    """Busca latitude e longitude de uma cidade."""
    try:
        url = f"https://geocoding-api.open-meteo.com/v1/search?name={city_name}&count=1&language=pt&format=json"
        response = requests.get(url)
        data = response.json()
        if not data.get("results"): return None, None
        location = data["results"][0]
        return location["latitude"], location["longitude"]
    except:
        return None, None

def get_weather_forecast(city_name: str):
    """ObtÃ©m a previsÃ£o do tempo para os prÃ³ximos dias."""
    lat, lon = get_coordinates(city_name)
    if lat is None: return f"Erro: Cidade '{city_name}' nÃ£o encontrada."

    url = "https://api.open-meteo.com/v1/forecast"
    params = {
        "latitude": lat, "longitude": lon,
        "daily": "temperature_2m_max,temperature_2m_min,precipitation_sum,weathercode",
        "forecast_days": 4, "timezone": "America/Sao_Paulo"
    }

    try:
        resp = requests.get(url, params=params).json()
        daily = resp.get("daily", {})
        
        report = []
        for i in range(len(daily.get("time", []))):
            code = daily["weathercode"][i]
            cond = WEATHER_MAP.get(code, "Desconhecido")
            report.append(
                f"- Data: {daily['time'][i]} | CondiÃ§Ã£o: {cond} | "
                f"MÃ¡x: {daily['temperature_2m_max'][i]}Â°C | "
                f"MÃ­n: {daily['temperature_2m_min'][i]}Â°C | "
                f"Chuva: {daily['precipitation_sum'][i]}mm"
            )
        return "\n".join(report)
    except Exception as e:
        return f"Erro na API: {str(e)}"

# --- LÃ“GICA DO CHATBOT ---
api_key = os.getenv("GEMINI_API_KEY")
if api_key:
    # Configura o Gemini apenas se a chave for fornecida
    genai.configure(api_key=api_key)
    
    # Inicializa o HistÃ³rico de Chat na SessÃ£o (MemÃ³ria visual do Streamlit)
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Inicializa a SessÃ£o do Gemini (LÃ³gica do Modelo)
    if "chat_session" not in st.session_state:
        model = genai.GenerativeModel(
            model_name='gemini-2.5-flash',
            tools=[get_weather_forecast],
            system_instruction="""
            VocÃª Ã© um meteorologista simpÃ¡tico. Use a funÃ§Ã£o disponÃ­vel para ver o clima.
            Formate a resposta usando Markdown para deixÃ¡-la bonita (use negrito em temperaturas, emojis, etc).
            NÃ£o mostre dados tÃ©cnicos brutos, faÃ§a um resumo agradÃ¡vel.
            """
        )
        st.session_state.chat_session = model.start_chat(enable_automatic_function_calling=True)

    # 1. Exibir mensagens antigas na tela
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # 2. Capturar nova entrada do usuÃ¡rio
    if prompt := st.chat_input("Pergunte sobre o clima (ex: Vai chover em SP amanhÃ£?)"):
        
        # Exibe a mensagem do usuÃ¡rio
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Processamento da IA
        with st.chat_message("assistant"):
            with st.spinner("Consultando satÃ©lites e modelos meteorolÃ³gicos..."):
                try:
                    # Envia para o Gemini
                    response = st.session_state.chat_session.send_message(prompt)
                    
                    # Exibe a resposta
                    st.markdown(response.text)
                    
                    # Salva no histÃ³rico
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    st.error(f"Ocorreu um erro: {e}")
else:
    st.warning("ğŸ‘ˆ Por favor, insira sua API Key na barra lateral para comeÃ§ar.")